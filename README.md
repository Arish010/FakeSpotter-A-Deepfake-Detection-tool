						FakeSpotter: Deepfake Detection (CNN) ? LSTM + Django App)

Overview:
FakeSpotter is an end-to-end deepfake detection system which:
- extracts frames from videos,
- computes frame embeddings using a pre-trained CNN backbone,
- models temporal patterns with an LSTM,
- calibrates decision thresholds (real / fake / uncertain),
- serves predictions via a Django web app.

---------------------------------------------------------------------------------
Features:
- Hybrid model: CNN embeddings + LSTM sequence classifier
- Calibrated outputs: real / fake / uncertain with a tunable margin
- Fast iteration: cached frame features (no need to re-extract every run)
- Web UI: upload video ? get prediction (no retraining at startup)

---------------------------------------------------------------------------------
Repository Structure:
FakeSpotter/
├─ Django_Application/
│  ├─ ml_app/
│  │  ├─ views.py
│  │  ├─ settings.py                 # paths & thresholds
│  │  └─ ...
│  └─ manage.py
├─ data/
│  ├─ raw_videos/                 	  # your input videos (real/fake)
│  ├─ extracted_frames/           	  # auto-created
│  └─ extracted_features/         	  # auto-created (cached .npy)
├─ models/
│  ├─ lstm_binary_weights.pth         # saved model checkpoints
│  └─ ...
├─ splits/ or splits_bin/         	  # csv/json splits generated by training
├─ scripts/                     		  # if you keep scripts in a folder
│  ├─ sample_1.py
│  ├─ extract_frames_2.py
│  ├─ extract_features_3.py
│  ├─ train_lstm_4.py
│  ├─ calibrate_threshold_5.py
│  ├─ evaluate_test_6.py
│  └─ predict_7.py
├─ best_threshold.json                 # output from calibration
├─ requirements.txt
└─ README.docx

---------------------------------------------------------------------------------

Requirements:
- Python 3.10+ (works on 3.12 as tested)
- PyTorch + TorchVision (CUDA optional)
- OpenCV, NumPy, scikit-learn, Pillow
- Django (for the web app)

Minimal requirements.txt:
torch
torchvision
opencv-python
numpy
scikit-learn
pillow
django
tqdm

---------------------------------------------------------------------------------
Setup:
pip install -r requirements.txt

---------------------------------------------------------------------------------

Configuration:
In Django_Application/ml_app/settings.py:

PROJECT_DIR = r"C:\Users\Asus\Desktop\Project Msc\Deepfake_detection_using_deep_learning"
FRAMES_DIR  = rf"{PROJECT_DIR}\extracted_frames"
FEATS_DIR   = rf"{PROJECT_DIR}\extracted_features"
MODELS_DIR  = rf"{PROJECT_DIR}\models"

LSTM_WEIGHTS_PATH = rf"{PROJECT_DIR}\lstm_binary_weights.pth"
CALIBRATED_THRESHOLD_PATH = rf"{PROJECT_DIR}\best_threshold.json"
UNCERTAIN_BAND = 0.05

IMG_SIZE     = 224
MAX_SEQ_LEN  = 60
BATCH_SIZE   = 32
EPOCHS       = 30

---------------------------------------------------------------------------------
Data Preparation:

Place your videos under data/raw_videos/ with folders 'real' and 'fake'.
Example:
data/raw_videos/
├─ real/
│  ├─ vid1.mp4
└─ fake/
   ├─ vidA.mp4

---------------------------------------------------------------------------------

Workflow:

1) Sample videos (optional)

python sample_1.py data/raw_videos --max_per_class 300

2) Extract frames

python extract_frames_2.py data/raw_videos --out data/extracted_frames --fps 5 --max_frames 120

3) Extract CNN features

python extract_features_3.py data/extracted_frames --out data/extracted_features --img_size 224 --backbone resnext50_32x4d

4) Train LSTM model

python train_lstm_4.py --feats data/extracted_features --out models/lstm_binary_weights.pth --max_seq_len 60 --batch_size 32 --epochs 30 --lr 
1e-3 --dropout 0.3

5) Calibrate threshold

python calibrate_threshold_5.py --feats data/extracted_features --weights models/lstm_binary_weights.pth --out best_threshold.json

6) Evaluate on test set

python evaluate_test_6.py --feats data/extracted_features --weights models/lstm_binary_weights.pth --thr_file best_threshold.json --report 
out_test_report.txt

7) Predict on new videos

python predict_7.py path\to\new_video_or_folder --weights models/lstm_binary_weights.pth --thr_file best_threshold.json --uncertain_band 0.05

---------------------------------------------------------------------------------

Running the Web App:
1) Confirm paths in Django_Application/ml_app/settings.py
2) Run the server:
cd Django_Application  	(access the Django_Application folder/       
open the folder in integrated terminal)
python manage.py runserver
3) Open -  http://127.0.0.1:8000/ in browser
4) Upload video (.mp4)
5) System will extract frames, compute embeddings, run LSTM, and output decision (REAL / FAKE).
Interpreting Outputs:
- P(real), P(fake): class probabilities
- Decision:
   If P(real) >= thr + band ? REAL
   If P(real) <= thr - band ? FAKE

--------------------------------------------------------------------------------- 

Tips:
- Keep extracted_features/ to avoid recomputing embeddings.
- Cap frames per video (max 60 120) and lower fps for speed.
- Use GPU if available; otherwise reduce MAX_SEQ_LEN and batch size for CPU.

---------------------------------------------------------------------------------

Troubleshooting:
- Try/except errors: ensure all try statements have an except or finally clause.
- Check model paths if checkpoint not loading.
- Overfitting: increase dropout, use early stopping, or add augmentations.
- Threshold issues: re-run calibration and adjust UNCERTAIN_BAND.
---------------------------------------------------------------------------------

Disclaimer:
FakeSpotter is a decision-support tool. It may produce errors, including false positives/negatives. Human review is advised for critical use cases. 
IMPORTANT NOTE:
The model might show inconsistency at the first upload, depending on previous cache or system compatibility. But it will give proper outputs after that.

